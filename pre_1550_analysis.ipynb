{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B28OreCpF7mm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import os\n",
        "\n",
        "from io import StringIO\n",
        "from google.colab import drive\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "from matplotlib.lines import Line2D\n",
        "from scipy.stats import mannwhitneyu, pearsonr, spearmanr, gaussian_kde\n",
        "\n",
        "# OPTIONAL: Load data from local or online source\n",
        "# If running on Colab and using Google Drive, uncomment below:\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/MyDrive/your_project_folder')\n",
        "\n",
        "# Otherwise, place your data in the same folder or set the correct relative path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_early   = pd.read_csv(\"data/pca_normalized_early.csv\")\n",
        "kpca_early  = pd.read_csv(\"data/kpca_normalized_early.csv\")\n",
        "wpca_early  = pd.read_csv(\"data/wpca_normalized_early.csv\")"
      ],
      "metadata": {
        "id": "ci21WP14F_sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enso1_file_path = 'data/enso1_reconstruction.txt'\n",
        "enso_df = pd.read_csv(enso1_file_path, sep=r'\\s+', comment='#')\n",
        "enso_df = enso_df.rename(columns={'age': 'Year_Bin', 'ensoi': 'ENSO'})\n",
        "enso_df['ENSO_norm'] = (enso_df['ENSO'] - enso_df['ENSO'].mean()) / enso_df['ENSO'].std()"
      ],
      "metadata": {
        "id": "FNKwhCX0GBy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdo1_file_path = 'data/pdo1_reconstruction.txt'\n",
        "pdo_df = pd.read_csv(pdo1_file_path, sep=r'\\s+', comment='#')\n",
        "pdo_df = pdo_df.rename(columns={'age': 'Year_Bin', 'pdo': 'PDO'})\n",
        "pdo_df['Year_Bin'] = pdo_df['Year_Bin'].astype(int)\n",
        "pdo_df['PDO_norm'] = (pdo_df['PDO'] - pdo_df['PDO'].mean()) / pdo_df['PDO'].std()"
      ],
      "metadata": {
        "id": "FClOZrlFJR5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipo_file_path = 'data/pdo2_reconstruction.txt'\n",
        "ipo_df = pd.read_csv(ipo_file_path, sep=r'\\s+', comment='#')\n",
        "ipo_df.columns = ['Year_Bin', 'IPO', 'Std_Dev']\n",
        "ipo_df['Year_Bin'] = ipo_df['Year_Bin'].astype(int)\n",
        "ipo_df['IPO_norm'] = (ipo_df['IPO'] - ipo_df['IPO'].mean()) / ipo_df['IPO'].std()"
      ],
      "metadata": {
        "id": "8L-azgODf8dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co2_df = pd.read_csv('data/co2-long-term-concentration.csv')\n",
        "co2_df.rename(columns={'Annual concentration of atmospheric carbon dioxide': 'CO2', 'Year':'Year_Bin'}, inplace=True)\n",
        "co2_df = co2_df[['Year_Bin', 'CO2']].copy()\n",
        "co2_df['Year_Bin'] = co2_df['Year_Bin'].astype(int)\n",
        "co2_df = co2_df[(co2_df['Year_Bin'] >= 1) & (co2_df['Year_Bin'] <= 2016)]\n",
        "co2_df['CO2_norm'] = (co2_df['CO2'] - co2_df['CO2'].mean()) / co2_df['CO2'].std()"
      ],
      "metadata": {
        "id": "6TaNLsTgdIJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsi_file_path = 'data/tsi_reconstruction.txt'\n",
        "with open(tsi_file_path, 'r', encoding='latin1') as file:\n",
        "    lines = file.read().splitlines()\n",
        "\n",
        "start_idx = next(i for i, line in enumerate(lines) if line.strip()[:1].isdigit())\n",
        "data_str = '\\n'.join(lines[start_idx:])\n",
        "tsi_df = pd.read_csv(StringIO(data_str), sep=r'\\s+', names=['YearBP', 'dTSI', 'dTSI_sigma'])\n",
        "tsi_df['Year_AD'] = 1950 - tsi_df['YearBP']\n",
        "tsi_df = tsi_df[tsi_df['Year_AD'].between(1, 2016)]\n",
        "tsi_df['TSI'] = 1365.57 + tsi_df['dTSI']\n",
        "tsi_df['Year_Bin'] = np.floor(tsi_df['Year_AD']).astype(int)\n",
        "tsi_df = tsi_df[['Year_Bin', 'TSI']].copy()\n",
        "tsi_df['TSI_norm'] = (tsi_df['TSI'] - tsi_df['TSI'].mean()) / tsi_df['TSI'].std()"
      ],
      "metadata": {
        "id": "CgzgO7mrDsEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(df, colname):\n",
        "    grouped = df.groupby(\"Year_Bin\")[colname]\n",
        "    median = grouped.median()\n",
        "    p5 = grouped.quantile(0.05)\n",
        "    p95 = grouped.quantile(0.95)\n",
        "    return pd.DataFrame({\n",
        "        \"Year_Bin\": median.index,\n",
        "        \"median\": median.values,\n",
        "        \"p5\": p5.values,\n",
        "        \"p95\": p95.values\n",
        "    })\n",
        "\n",
        "pca_summary = summarize(pca_early, \"PC1_norm\")\n",
        "kpca_summary = summarize(kpca_early, \"KPC1_norm\")\n",
        "wpca_summary = summarize(wpca_early, \"WPC1_norm\")"
      ],
      "metadata": {
        "id": "QbvOi4g7G-nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Patch\n",
        "\n",
        "# Define investigation intervals (start year, end year)\n",
        "investigation_intervals = [\n",
        "    (500, 550),\n",
        "    (680, 730),\n",
        "    (1050, 1100),\n",
        "    (1140, 1250),\n",
        "    (1340, 1400),\n",
        "    (1460, 1550)\n",
        "]\n",
        "\n",
        "# Create plot\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Plot PCA reconstructions with uncertainty\n",
        "for summary, label, color in zip([pca_summary, kpca_summary, wpca_summary],\n",
        "                                 ['Standard PCA', 'Kernel PCA', 'Wavelet PCA'],\n",
        "                                 ['blue', 'green', 'orange']):\n",
        "    ax.plot(summary[\"Year_Bin\"], summary[\"median\"], label=label, color=color)\n",
        "    ax.fill_between(summary[\"Year_Bin\"], summary[\"p5\"], summary[\"p95\"], alpha=0.2, color=color)\n",
        "\n",
        "# Add boxed intervals and markers\n",
        "for start, end in investigation_intervals:\n",
        "    # Bracket lines\n",
        "    ax.axvline(x=start, color='black', linestyle='--', linewidth=1)\n",
        "    ax.axvline(x=end, color='black', linestyle='--', linewidth=1)\n",
        "\n",
        "    # Midpoint marker\n",
        "    midpoint = (start + end) / 2\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    ax.plot(midpoint, ymin + (ymax - ymin) * 0.05, marker='*', color='black', markersize=8)\n",
        "\n",
        "\n",
        "handles = [\n",
        "    Patch(facecolor='gray', edgecolor='gray', alpha=0.15, label='5–95% Percentile Bound'),\n",
        "    plt.Line2D([], [], color='blue', linewidth=2, label='Median PC1 (Standard)'),\n",
        "    plt.Line2D([], [], color='green', linewidth=2, label='Median KPC1 (Kernel)'),\n",
        "    plt.Line2D([], [], color='orange', linewidth=2, label='Median WPC1 (Wavelet)')\n",
        "]\n",
        "\n",
        "# Styling\n",
        "ax.set_ylabel(\"PC1 (Normalized)\", fontsize=12)\n",
        "ax.set_xlabel(\"Year\", fontsize=12)\n",
        "ax.set_title(\"Hydroclimate Variability Reconstruction (1–1550 CE)\", fontsize=14)\n",
        "ax.set_xlim(0, 1550)\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_linewidth(1)\n",
        "    spine.set_color('black')\n",
        "\n",
        "ax.legend(handles=handles, loc='upper left')\n",
        "ax.set_xlabel(\"Year\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sa8lGU3dye15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define investigation intervals (start year, end year)\n",
        "investigation_intervals = [\n",
        "    (500, 550),\n",
        "    (680, 730),\n",
        "    (1050, 1100),\n",
        "    (1140, 1250),\n",
        "    (1340, 1400),\n",
        "    (1460, 1550)\n",
        "]\n",
        "\n",
        "fig, axs = plt.subplots(5, 1, figsize=(15, 14), sharex=True, gridspec_kw={'height_ratios': [2, 1, 1, 1, 1]})\n",
        "\n",
        "for ax in axs:\n",
        "    ax.set_xlim(0, 1550)\n",
        "    ax.xaxis.set_major_locator(MultipleLocator(100))\n",
        "    ax.tick_params(labelbottom=True, labelsize=12)  # x-ticks font size\n",
        "    ax.tick_params(labelleft=True, labelsize=12)    # y-ticks font size\n",
        "    ax.grid(True, axis='x', linestyle='--', color='gray', linewidth=0.8, alpha=0.6)\n",
        "\n",
        "# Shade intervals across all subplots\n",
        "for start, end in investigation_intervals:\n",
        "    for ax in axs:\n",
        "        ax.axvspan(start, end, color='goldenrod', alpha=0.2)\n",
        "\n",
        "# Hydroclimate Reconstruction\n",
        "for summary, label, color in zip([pca_summary, kpca_summary, wpca_summary],\n",
        "                                 ['Standard PCA', 'Kernel PCA', 'Wavelet PCA'],\n",
        "                                 ['blue', 'green', 'orange']):\n",
        "    axs[0].plot(summary[\"Year_Bin\"], summary[\"median\"], label=label, color=color)\n",
        "    axs[0].fill_between(summary[\"Year_Bin\"], summary[\"p5\"], summary[\"p95\"], alpha=0.2, color=color)\n",
        "\n",
        "axs[0].set_ylabel(\"PC1 (Normalized)\", fontsize=12)\n",
        "axs[0].set_title(\"Hydroclimate Variability Reconstruction (Pre-1550 CE)\", fontsize=14)\n",
        "axs[0].legend()\n",
        "\n",
        "# Volcanic eruption years\n",
        "eruption_years = [653, 683, 710]\n",
        "\n",
        "eruption_y = axs[0].get_ylim()[0] - 0.05\n",
        "\n",
        "axs[0].scatter(\n",
        "    eruption_years,\n",
        "    [eruption_y] * len(eruption_years),\n",
        "    marker='^', color='red', s=80, label='Volcanic Eruption'\n",
        ")\n",
        "\n",
        "axs[0].set_ylim(eruption_y - 0.1, axs[0].get_ylim()[1])\n",
        "axs[0].legend(loc='upper left', fontsize=12)\n",
        "\n",
        "# ENSO, PDO, TSI, CO2 (filtered to pre-1550)\n",
        "axs[1].plot(enso_df[enso_df[\"Year_Bin\"] <= 1550][\"Year_Bin\"], enso_df[enso_df[\"Year_Bin\"] <= 1550][\"ENSO_norm\"], color='darkcyan')\n",
        "axs[1].set_ylabel(\"ENSO (Normalized)\", fontsize=12)\n",
        "axs[1].set_title(\"ENSO Reconstructions\", fontsize=14)\n",
        "\n",
        "axs[2].plot(pdo_df[pdo_df[\"Year_Bin\"] <= 1550][\"Year_Bin\"], pdo_df[pdo_df[\"Year_Bin\"] <= 1550][\"PDO_norm\"], color='brown', label='PDO')\n",
        "axs[2].plot(ipo_df[ipo_df[\"Year_Bin\"] <= 1550][\"Year_Bin\"], ipo_df[ipo_df[\"Year_Bin\"] <= 1550][\"IPO_norm\"], color='olive', label='IPO')\n",
        "axs[2].set_ylabel(\"PDO (Normalized)\", fontsize=12)\n",
        "axs[2].set_title(\"PDO/IPO Reconstructions\", fontsize=14)\n",
        "axs[2].legend(loc='upper left', fontsize=12)\n",
        "\n",
        "axs[3].plot(tsi_df[tsi_df[\"Year_Bin\"] <= 1550][\"Year_Bin\"], tsi_df[tsi_df[\"Year_Bin\"] <= 1550][\"TSI_norm\"], color='crimson')\n",
        "axs[3].set_ylabel(\"TSI (Normalized)\", fontsize=12)\n",
        "axs[3].set_title(\"TSI Reconstruction\", fontsize=14)\n",
        "\n",
        "axs[4].plot(co2_df[co2_df[\"Year_Bin\"] <= 1550][\"Year_Bin\"], co2_df[co2_df[\"Year_Bin\"] <= 1550][\"CO2_norm\"], color='magenta')\n",
        "axs[4].set_ylabel(\"CO2 (Normalized)\", fontsize=12)\n",
        "axs[4].set_xlabel(\"Year (CE)\", fontsize=12)\n",
        "axs[4].set_title(\"CO2 Reconstruction\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HLyVvR3A-BT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def bin_and_normalize(df, value_col):\n",
        "    df = df.copy()\n",
        "    df['Year_Bin'] = ((df['Year_Bin'] - 1) // 10) * 10 + 1\n",
        "    df_binned = df.groupby('Year_Bin')[value_col].mean().reset_index()\n",
        "\n",
        "    # Normalize after binning\n",
        "    scaler = StandardScaler()\n",
        "    df_binned[f'{value_col}_norm'] = scaler.fit_transform(df_binned[[value_col]])\n",
        "    return df_binned[['Year_Bin', f'{value_col}_norm']]\n",
        "\n",
        "# Apply to all forcings\n",
        "enso_binned = bin_and_normalize(enso_df, 'ENSO')\n",
        "pdo_binned = bin_and_normalize(pdo_df, 'PDO')\n",
        "ipo_binned = bin_and_normalize(ipo_df, 'IPO')\n",
        "tsi_binned = bin_and_normalize(tsi_df, 'TSI')\n",
        "co2_binned = bin_and_normalize(co2_df, 'CO2')"
      ],
      "metadata": {
        "id": "QCrBlclF-4rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "investigation_intervals = [\n",
        "    (500, 550),\n",
        "    (680, 730),\n",
        "    (1050, 1100),\n",
        "    (1140, 1250),\n",
        "    (1340, 1400),\n",
        "    (1460, 1550)\n",
        "]\n",
        "\n",
        "# PCA info\n",
        "pca_info = [\n",
        "    (\"Standard\", pca_early, \"PC1_norm\"),\n",
        "    (\"Kernel\", kpca_early, \"KPC1_norm\"),\n",
        "    (\"Wavelet\", wpca_early, \"WPC1_norm\")\n",
        "]\n",
        "\n",
        "# Forcing datasets (binned and normalized)\n",
        "forcing_dfs = {\n",
        "    'ENSO': enso_binned,\n",
        "    'PDO': pdo_binned,\n",
        "    'IPO': ipo_binned,\n",
        "    'TSI': tsi_binned,\n",
        "    'CO2': co2_binned,\n",
        "}\n",
        "\n",
        "forcing_colors = {\n",
        "    'ENSO': 'blue',\n",
        "    'PDO': 'orange',\n",
        "    'IPO': 'green',\n",
        "    'TSI': 'red',\n",
        "    'CO2': 'magenta',\n",
        "}"
      ],
      "metadata": {
        "id": "R5s1RgGL8ZNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(20, 6), sharey=True)\n",
        "\n",
        "for ax, (pca_label, pca_df, pc1_col) in zip(axes, pca_info):\n",
        "    all_corrs = {forcing: [] for forcing in forcing_dfs}\n",
        "    sig_corrs = {forcing: [] for forcing in forcing_dfs}\n",
        "\n",
        "    for realization in pca_df['Realization'].unique():\n",
        "        realization_df = pca_df[pca_df['Realization'] == realization][['Year_Bin', pc1_col]]\n",
        "\n",
        "        for forcing_name, forcing_df in forcing_dfs.items():\n",
        "            merged = pd.merge(realization_df, forcing_df, on='Year_Bin', how='inner').dropna()\n",
        "            if len(merged) > 2:\n",
        "                corr, pval = pearsonr(merged[pc1_col], merged.iloc[:, 2])\n",
        "                abs_corr = abs(corr)\n",
        "                all_corrs[forcing_name].append(abs_corr)\n",
        "                if pval < 0.05:\n",
        "                    sig_corrs[forcing_name].append(abs_corr)\n",
        "\n",
        "    # Plot KDEs\n",
        "    for i, (forcing_name, corr_values) in enumerate(all_corrs.items()):\n",
        "        if len(corr_values) > 0:\n",
        "            color = forcing_colors.get(forcing_name, 'gray')\n",
        "            # Plot main KDE\n",
        "            sns.kdeplot(corr_values, label=forcing_name, ax=ax, color=color, linewidth=2)\n",
        "\n",
        "            if sig_corrs[forcing_name]:\n",
        "                kde = gaussian_kde(corr_values, bw_method=0.75)\n",
        "                x_vals = np.linspace(0, 1, 500)\n",
        "                y_vals = kde(x_vals)\n",
        "                min_sig = min(sig_corrs[forcing_name])\n",
        "                max_sig = max(sig_corrs[forcing_name])\n",
        "                mask = (x_vals >= min_sig) & (x_vals <= max_sig) & (y_vals > 1e-3)\n",
        "                ax.fill_between(x_vals[mask], 0, y_vals[mask], color=color, alpha=0.3)\n",
        "\n",
        "            # Median line\n",
        "            median_corr = np.median(corr_values)\n",
        "            ax.axvline(median_corr, color=color, linestyle=':', linewidth=1.5, alpha=0.7)\n",
        "\n",
        "            # Annotate % significant\n",
        "            percent_sig = 100 * len(sig_corrs[forcing_name]) / len(corr_values)\n",
        "            ax.annotate(\n",
        "                f\"{forcing_name}: {percent_sig:.1f}%\",\n",
        "                xy=(1.02, 0.95 - 0.08 * i),\n",
        "                xycoords='axes fraction',\n",
        "                fontsize=10,\n",
        "                color=color,\n",
        "                ha='left',\n",
        "                va='top'\n",
        "            )\n",
        "\n",
        "    ax.set_xlim(0, 0.6)\n",
        "    ax.set_xticks(np.linspace(0, 0.6, 7))\n",
        "    ax.set_title(f'{pca_label} PCA', fontsize=14)\n",
        "    ax.set_xlabel('|Correlation|', fontsize=12)\n",
        "    ax.grid(True, linestyle='--', alpha=0.3)\n",
        "    ax.tick_params(labelsize=11)\n",
        "\n",
        "axes[0].set_ylabel('Density', fontsize=12)\n",
        "\n",
        "# Common legend for all forcings\n",
        "custom_handles = [\n",
        "    Line2D([0], [0], color=forcing_colors[forcing], lw=2)\n",
        "    for forcing in forcing_dfs.keys()\n",
        "]\n",
        "fig.legend(\n",
        "    custom_handles,\n",
        "    list(forcing_dfs.keys()),\n",
        "    loc='lower center',\n",
        "    bbox_to_anchor=(0.5, -0.1),\n",
        "    ncol=5,\n",
        "    frameon=False,\n",
        "    fontsize=11,\n",
        "    title=\"Forcings\",\n",
        "    title_fontsize=12\n",
        ")\n",
        "fig.suptitle(\n",
        "    \"Distribution of Absolute Correlations (|r|) Between PCA Realisations and Climate Forcings\\n(Shading: Significant Correlations, p<0.05; Dotted Line: Median)\",\n",
        "    fontsize=14,\n",
        "    y=0.98\n",
        ")\n",
        "plt.tight_layout(rect=[0, 0.05, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DvQEMcAYE_Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kde_baseline_vs_anomaly(start, end, pca_info, forcing_dfs, forcing_colors):\n",
        "    baseline_start, baseline_end = start - 50, start\n",
        "    interval = f\"{start}-{end}\"\n",
        "    baseline_label = f\"{baseline_start}-{baseline_end}\"\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n",
        "\n",
        "    for ax, (pca_label, pca_df, pc1_col) in zip(axes, pca_info):\n",
        "        # Hydroclimate data\n",
        "        baseline_pca = pca_df[(pca_df[\"Year_Bin\"] >= baseline_start) & (pca_df[\"Year_Bin\"] < baseline_end)]\n",
        "        anomaly_pca = pca_df[(pca_df[\"Year_Bin\"] >= start) & (pca_df[\"Year_Bin\"] <= end)]\n",
        "\n",
        "        for i, (forcing_name, forcing_df) in enumerate(forcing_dfs.items()):\n",
        "            color = forcing_colors.get(forcing_name, 'gray')\n",
        "\n",
        "            # Forcing data\n",
        "            baseline_forcing = forcing_df[(forcing_df['Year_Bin'] >= baseline_start) & (forcing_df['Year_Bin'] < baseline_end)]\n",
        "            anomaly_forcing = forcing_df[(forcing_df['Year_Bin'] >= start) & (forcing_df['Year_Bin'] <= end)]\n",
        "\n",
        "            # Correlations storage\n",
        "            baseline_corrs = []\n",
        "            baseline_sig = 0\n",
        "            anomaly_corrs = []\n",
        "            anomaly_sig = 0\n",
        "\n",
        "            for r in anomaly_pca[\"Realization\"].unique():\n",
        "                baseline_r = baseline_pca[baseline_pca[\"Realization\"] == r][['Year_Bin', pc1_col]]\n",
        "                anomaly_r = anomaly_pca[anomaly_pca[\"Realization\"] == r][['Year_Bin', pc1_col]]\n",
        "\n",
        "                merged_baseline = pd.merge(baseline_r, baseline_forcing, on='Year_Bin', how='inner').dropna()\n",
        "                merged_anomaly = pd.merge(anomaly_r, anomaly_forcing, on='Year_Bin', how='inner').dropna()\n",
        "\n",
        "                if len(merged_baseline) > 2:\n",
        "                    corr_b, pval_b = pearsonr(merged_baseline[pc1_col], merged_baseline.iloc[:, 2])\n",
        "                    baseline_corrs.append(abs(corr_b))\n",
        "                    if pval_b < 0.05:\n",
        "                        baseline_sig += 1\n",
        "\n",
        "                if len(merged_anomaly) > 2:\n",
        "                    corr_a, pval_a = pearsonr(merged_anomaly[pc1_col], merged_anomaly.iloc[:, 2])\n",
        "                    anomaly_corrs.append(abs(corr_a))\n",
        "                    if pval_a < 0.05:\n",
        "                        anomaly_sig += 1\n",
        "\n",
        "            # Plotting\n",
        "            if baseline_corrs:\n",
        "                kde_baseline = gaussian_kde(baseline_corrs, bw_method=0.75)\n",
        "                x_vals = np.linspace(0, 1, 500)\n",
        "                y_vals = kde_baseline(x_vals)\n",
        "                ax.plot(x_vals, y_vals, linestyle='--', color=color, linewidth=1.8, alpha=0.7)  # dashed = baseline\n",
        "\n",
        "            if anomaly_corrs:\n",
        "                kde_anomaly = gaussian_kde(anomaly_corrs, bw_method=0.75)\n",
        "                x_vals = np.linspace(0, 1, 500)\n",
        "                y_vals = kde_anomaly(x_vals)\n",
        "                ax.plot(x_vals, y_vals, linestyle='-', color=color, linewidth=2.5, alpha=0.9)  # solid = anomaly\n",
        "\n",
        "            # Annotate % significant (inside the plot)\n",
        "            total_baseline = len(baseline_corrs)\n",
        "            total_anomaly = len(anomaly_corrs)\n",
        "\n",
        "            if total_baseline > 0:\n",
        "                baseline_percent_sig = 100 * baseline_sig / total_baseline\n",
        "                ax.annotate(\n",
        "                    f\"{forcing_name} Baseline: {baseline_percent_sig:.1f}%\",\n",
        "                    xy=(1.02, 0.95 - 0.08 * (i * 2)),\n",
        "                    xycoords='axes fraction',\n",
        "                    fontsize=11,\n",
        "                    color=color,\n",
        "                    ha='left',\n",
        "                    va='top'\n",
        "                )\n",
        "\n",
        "            if total_anomaly > 0:\n",
        "                anomaly_percent_sig = 100 * anomaly_sig / total_anomaly\n",
        "                ax.annotate(\n",
        "                    f\"{forcing_name} Anomaly: {anomaly_percent_sig:.1f}%\",\n",
        "                    xy=(1.02, 0.95 - 0.08 * (i * 2 + 1)),\n",
        "                    xycoords='axes fraction',\n",
        "                    fontsize=11,\n",
        "                    color=color,\n",
        "                    ha='left',\n",
        "                    va='top'\n",
        "                )\n",
        "\n",
        "        ax.set_xlim(0, 1)\n",
        "        ax.set_xticks(np.linspace(0, 1, 6))\n",
        "        ax.tick_params(axis='both', labelsize=11)\n",
        "        ax.set_title(f\"{pca_label} PCA\")\n",
        "        ax.set_xlabel(\"|Pearson Correlation|\", fontsize=12)\n",
        "        ax.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "    axes[0].set_ylabel(\"Density\", fontsize=12)\n",
        "\n",
        "    # Legend\n",
        "    custom_handles = [\n",
        "        Line2D([0], [0], color=forcing_colors[forcing], lw=2)\n",
        "        for forcing in forcing_dfs.keys()\n",
        "    ]\n",
        "    style_handles = [\n",
        "        Line2D([0], [0], color='black', lw=2, linestyle='-', label=\"Anomaly\"),\n",
        "        Line2D([0], [0], color='black', lw=2, linestyle='--', label=\"Baseline\")\n",
        "    ]\n",
        "    fig.legend(\n",
        "        custom_handles + style_handles,\n",
        "        list(forcing_dfs.keys()) + [\"Anomaly\", \"Baseline\"],\n",
        "        loc='lower center',\n",
        "        bbox_to_anchor=(0.5, -0.08),\n",
        "        ncol=7,\n",
        "        frameon=False,\n",
        "        fontsize=12\n",
        "    )\n",
        "\n",
        "    fig.suptitle(\n",
        "        f\"KDE of |r|: Baseline ({baseline_label}) vs Anomaly ({interval})\\n(Solid = Anomaly, Dashed = Baseline)\",\n",
        "        y=0.98,\n",
        "        fontsize=16\n",
        "    )\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.02, 1, 0.98])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rQ6rZXKyTSql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each investigation interval\n",
        "for start, end in investigation_intervals:\n",
        "    plot_kde_baseline_vs_anomaly(\n",
        "        start=start,\n",
        "        end=end,\n",
        "        pca_info=pca_info,\n",
        "        forcing_dfs=forcing_dfs,\n",
        "        forcing_colors=forcing_colors\n",
        "    )"
      ],
      "metadata": {
        "id": "PUUBBgoJTVi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}