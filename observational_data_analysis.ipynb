{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMiGfc62Lwix"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.stats import spearmanr\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "# OPTIONAL: Load data from local or online source\n",
        "# If running on Colab and using Google Drive, uncomment below:\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/MyDrive/your_project_folder')\n",
        "\n",
        "# Otherwise, place your data in the same folder or set the correct relative path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_recent   = pd.read_csv(\"data/pca_normalized_recent.csv\")\n",
        "kpca_recent  = pd.read_csv(\"data/kpca_normalized_recent.csv\")\n",
        "wpca_recent  = pd.read_csv(\"data/wpca_normalized_recent.csv\")"
      ],
      "metadata": {
        "id": "0C2_kqkjLxmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.cpc.ncep.noaa.gov/data/indices/oni.ascii.txt\"\n",
        "response = requests.get(url)\n",
        "raw_text = response.text\n",
        "df = pd.read_csv(StringIO(raw_text), sep='\\s+')\n",
        "\n",
        "enso_df = (\n",
        "    df\n",
        "    .groupby('YR', as_index=False)\n",
        "    .agg({'ANOM': 'mean'})\n",
        "    .rename(columns={'YR': 'Year_Bin', 'ANOM': 'ENSO'})\n",
        ")\n",
        "\n",
        "enso_df['ENSO_norm'] = (enso_df['ENSO'] - enso_df['ENSO'].mean()) / enso_df['ENSO'].std()\n",
        "enso_df = enso_df[enso_df['Year_Bin'] <= 2016]\n",
        "enso_df.head()"
      ],
      "metadata": {
        "id": "vYUBJ87ULy1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdo_df = pd.read_csv('data/pdo.timeseries.ersstv5.csv')\n",
        "pdo_df['Date'] = pd.to_datetime(pdo_df['Date'])\n",
        "pdo_df['Year_Bin'] = pdo_df['Date'].dt.year\n",
        "pdo_df = pdo_df.rename(columns={pdo_df.columns[1]: 'PDO'})\n",
        "pdo_df = pdo_df.groupby('Year_Bin')['PDO'].mean().reset_index()\n",
        "pdo_df['PDO_norm'] = (pdo_df['PDO'] - pdo_df['PDO'].mean()) / pdo_df['PDO'].std()\n",
        "pdo_df = pdo_df[pdo_df['Year_Bin'] <= 2016]\n",
        "pdo_df.head()"
      ],
      "metadata": {
        "id": "mKfyjXKGNxmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and clean the data\n",
        "data = []\n",
        "with open(\"data/composite_d25_07_0310a.dat\", \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i < 42:\n",
        "            continue  # Skip header\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) != 3:\n",
        "            continue\n",
        "        date, day_of_epoch, irradiance = parts\n",
        "        irradiance = float(irradiance)\n",
        "        if irradiance == -99.0000:\n",
        "            continue  # Skip missing values\n",
        "        data.append((date, float(day_of_epoch), irradiance))  # <-- fix here\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Date\", \"DayOfEpoch\", \"Irradiance\"])\n",
        "\n",
        "# Step 3: Extract full year from YYMMDD\n",
        "def parse_year(ymd):\n",
        "    y = int(ymd[:2])\n",
        "    return 1900 + y if y >= 78 else 2000 + y\n",
        "\n",
        "df[\"YR\"] = df[\"Date\"].apply(parse_year)\n",
        "\n",
        "# Step 4: Group and bin\n",
        "tsi_df = (\n",
        "    df.groupby(\"YR\", as_index=False)\n",
        "    .agg({\"Irradiance\": \"mean\"})\n",
        "    .rename(columns={'YR': 'Year_Bin', 'Irradiance': 'TSI'})\n",
        ")\n",
        "\n",
        "tsi_df['TSI_norm'] = (tsi_df['TSI'] - tsi_df['TSI'].mean()) / tsi_df['TSI'].std()\n",
        "tsi_df = tsi_df[tsi_df['Year_Bin'] <= 2016]\n",
        "tsi_df.head()"
      ],
      "metadata": {
        "id": "4ey49qWsOuGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co2_df = pd.read_csv('data/co2_gr_mlo.csv', skiprows=45)\n",
        "co2_df = co2_df.rename(columns={'year': 'Year_Bin', 'ann inc': 'CO2'})\n",
        "co2_df['CO2_norm'] = (co2_df['CO2'] - co2_df['CO2'].mean()) / co2_df['CO2'].std()\n",
        "co2_df = co2_df[co2_df['Year_Bin'] <= 2016]\n",
        "co2_df.head()"
      ],
      "metadata": {
        "id": "zKRFb0_kPJlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute median and 5â€“95 percentile for each PCA\n",
        "def summarize(df, colname):\n",
        "    grouped = df.groupby(\"Year_Bin\")[colname]\n",
        "    median = grouped.median()\n",
        "    p5 = grouped.quantile(0.05)\n",
        "    p95 = grouped.quantile(0.95)\n",
        "    return pd.DataFrame({\n",
        "        \"Year_Bin\": median.index,\n",
        "        \"median\": median.values,\n",
        "        \"p5\": p5.values,\n",
        "        \"p95\": p95.values\n",
        "    })\n",
        "\n",
        "pca_summary = summarize(pca_recent, \"PC1_norm\")\n",
        "pca_summary = pca_summary[pca_summary[\"Year_Bin\"] >= 1950]\n",
        "\n",
        "kpca_summary = summarize(kpca_recent, \"KPC1_norm\")\n",
        "kpca_summary = kpca_summary[kpca_summary[\"Year_Bin\"] >= 1950]\n",
        "\n",
        "wpca_summary = summarize(wpca_recent, \"WPC1_norm\")\n",
        "wpca_summary = wpca_summary[wpca_summary[\"Year_Bin\"] >= 1950]"
      ],
      "metadata": {
        "id": "l6EuQfxdMAZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(5, 1, figsize=(14, 13), sharex=True, gridspec_kw={'height_ratios': [2, 1, 1, 1, 1]})\n",
        "\n",
        "for ax in axs:\n",
        "    ax.xaxis.set_major_locator(MultipleLocator(20))\n",
        "    ax.tick_params(labelbottom=True)\n",
        "    ax.grid(True, axis='x', linestyle='--', color='gray', linewidth=0.8, alpha=0.6)\n",
        "\n",
        "# Panel 1: Hydroclimate Reconstruction\n",
        "for summary, label, color in zip([pca_summary, kpca_summary, wpca_summary],\n",
        "                                 ['Standard PCA', 'Kernel PCA', 'Wavelet PCA'],\n",
        "                                 ['blue', 'green', 'orange']):\n",
        "    axs[0].plot(summary[\"Year_Bin\"], summary[\"median\"], label=label, color=color)\n",
        "    axs[0].fill_between(summary[\"Year_Bin\"], summary[\"p5\"], summary[\"p95\"], alpha=0.2, color=color)\n",
        "\n",
        "axs[0].set_ylabel(\"PC1 (Normalized)\", fontsize=12)\n",
        "axs[0].set_title(\"Hydroclimate Variability Reconstruction\", fontsize=14)\n",
        "axs[0].legend()\n",
        "\n",
        "# Volcanic eruption years\n",
        "eruption_years = [1963, 1991]\n",
        "\n",
        "# Set y-position for triangle markers (just below the plot)\n",
        "eruption_y = axs[0].get_ylim()[0] - 0.05  # adjust this if needed\n",
        "\n",
        "# Plot upright red triangles\n",
        "axs[0].scatter(\n",
        "    eruption_years,\n",
        "    [eruption_y] * len(eruption_years),\n",
        "    marker='^', color='red', s=80, label='Volcanic Eruption'\n",
        ")\n",
        "\n",
        "# Adjust y-axis limit to make space for the triangles\n",
        "axs[0].set_ylim(eruption_y - 0.1, axs[0].get_ylim()[1])\n",
        "\n",
        "# Make sure it's added to the existing legend\n",
        "axs[0].legend(loc='upper left', fontsize=12)\n",
        "\n",
        "\n",
        "# Panel 2: ENSO\n",
        "axs[1].plot(enso_df[\"Year_Bin\"], enso_df[\"ENSO_norm\"], color='darkcyan')\n",
        "axs[1].set_ylabel(\"ENSO (Normalized)\", fontsize=12)\n",
        "axs[1].set_title(\"Observed ENSO\", fontsize=14)\n",
        "\n",
        "\n",
        "# Panel 3: PDO\n",
        "axs[2].plot(pdo_df[\"Year_Bin\"], pdo_df[\"PDO_norm\"], color='brown')\n",
        "axs[2].set_ylabel(\"PDO (Normalized)\", fontsize=12)\n",
        "axs[2].set_title(\"Observed PDO\", fontsize=14)\n",
        "\n",
        "\n",
        "# Panel 4: TSI\n",
        "axs[3].plot(tsi_df[\"Year_Bin\"], tsi_df[\"TSI_norm\"], color='crimson')\n",
        "axs[3].set_ylabel(\"TSI (Normalized)\", fontsize=12)\n",
        "axs[3].set_title(\"Observed TSI\", fontsize=14)\n",
        "\n",
        "# Panel 5: CO2\n",
        "axs[4].plot(co2_df[\"Year_Bin\"], co2_df[\"CO2_norm\"], color='magenta')\n",
        "axs[4].set_ylabel(\"CO2 (Normalized)\", fontsize=12)\n",
        "axs[4].set_xlabel(\"Year (CE)\", fontsize=12)\n",
        "axs[4].set_title(\"Observed CO2\", fontsize=14)\n",
        "\n",
        "for ax in axs:\n",
        "    ax.set_xlim(1950, 2016)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZwccPbdOMWdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_methods = {\n",
        "    'Standard PCA': (pca_recent, 'PC1_norm'),\n",
        "    'Kernel PCA': (kpca_recent, 'KPC1_norm'),\n",
        "    'Wavelet PCA': (wpca_recent, 'WPC1_norm')\n",
        "}\n",
        "\n",
        "forcing_datasets = {\n",
        "    'ENSO': enso_df[['Year_Bin', 'ENSO_norm']].rename(columns={'ENSO_norm': 'forcing'}),\n",
        "    'PDO': pdo_df[['Year_Bin', 'PDO_norm']].rename(columns={'PDO_norm': 'forcing'}),\n",
        "    'TSI': tsi_df[['Year_Bin', 'TSI_norm']].rename(columns={'TSI_norm': 'forcing'}),\n",
        "    'CO2': co2_df[['Year_Bin', 'CO2_norm']].rename(columns={'CO2_norm': 'forcing'})\n",
        "}\n",
        "\n",
        "# Analysis function\n",
        "def analyze_correlation(forcing_name, forcing_df):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
        "\n",
        "    for ax, (label, (pca_df, pc_col)) in zip(axs, pca_methods.items()):\n",
        "        pca_df_filtered = pca_df[pca_df['Year_Bin'] >= 1950]\n",
        "        forcing_df_filtered = forcing_df[forcing_df['Year_Bin'] >= 1950]\n",
        "        merged = pd.merge(pca_df_filtered, forcing_df_filtered, on='Year_Bin', how='inner')\n",
        "\n",
        "        observed_corrs = []\n",
        "        null_corrs = []\n",
        "\n",
        "        for r in merged['Realization'].unique():\n",
        "            subset = merged[merged['Realization'] == r]\n",
        "            corr_actual = np.corrcoef(subset[pc_col], subset['forcing'])[0,1]\n",
        "            observed_corrs.append(corr_actual)\n",
        "\n",
        "            for _ in range(50):\n",
        "                shuffled_pc1 = np.random.permutation(subset[pc_col])\n",
        "                corr_null = np.corrcoef(shuffled_pc1, subset['forcing'])[0,1]\n",
        "                null_corrs.append(corr_null)\n",
        "\n",
        "        # Plot\n",
        "        sns.kdeplot(null_corrs, ax=ax, color='grey', linestyle='--', label='Null Distribution (Shuffled)')\n",
        "        sns.kdeplot(observed_corrs, ax=ax, color='blue', label='Actual Correlations')\n",
        "\n",
        "        # Add medians\n",
        "        ax.axvline(np.median(null_corrs), color='grey', linestyle='dotted')\n",
        "        ax.axvline(np.median(observed_corrs), color='blue', linestyle='solid', linewidth=1)\n",
        "\n",
        "        # Mann-Whitney U Test\n",
        "        stat, p_val = mannwhitneyu(observed_corrs, null_corrs, alternative='two-sided')\n",
        "\n",
        "        # Legend and p-value positioning\n",
        "        ax.legend(loc='upper left', fontsize=10)\n",
        "        ax.text(0.05, 0.75, f'Mannâ€“Whitney p = {p_val:.4f}', transform=ax.transAxes, fontsize=10,\n",
        "                bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "        ax.set_title(f'{label} - {forcing_name}')\n",
        "        ax.set_xlabel('Pearson Correlation', fontsize=12)\n",
        "        ax.set_ylabel('Density', fontsize=12)\n",
        "        ax.tick_params(axis='both', labelsize=10)\n",
        "\n",
        "    fig.suptitle(f'Comparison of Observed vs Null Correlations: {forcing_name}', fontsize=14)\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    plt.show()\n",
        "\n",
        "# Run analysis for each forcing\n",
        "for forcing_name, forcing_df in forcing_datasets.items():\n",
        "    analyze_correlation(forcing_name, forcing_df)"
      ],
      "metadata": {
        "id": "bz_O6Zxlvm8w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}