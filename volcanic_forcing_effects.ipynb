{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# OPTIONAL: Load data from local or online source\n",
        "# If running on Colab and using Google Drive, uncomment below:\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/MyDrive/your_project_folder')\n",
        "\n",
        "# Otherwise, place your data in the same folder or set the correct relative path"
      ],
      "metadata": {
        "id": "bbpVXHjBFW84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_recent   = pd.read_csv(\"data/pca_normalized_recent.csv\")\n",
        "kpca_recent  = pd.read_csv(\"data/kpca_normalized_recent.csv\")\n",
        "wpca_recent  = pd.read_csv(\"data/wpca_normalized_recent.csv\")"
      ],
      "metadata": {
        "id": "8sfjiq9M7Pnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load volcano data\n",
        "volcano_df = pd.read_csv(os.path.join(base_path, 'data/volcano-events.csv'))\n",
        "\n",
        "significant_eruptions_recent = volcano_df[\n",
        "    (volcano_df['VEI'] >= 5) & (volcano_df['Year'] >= 1)\n",
        "].copy()\n",
        "\n",
        "significant_eruptions_recent['Year_Bin'] = significant_eruptions_recent['Year'].astype(int)\n",
        "\n",
        "eruption_years_recent = significant_eruptions_recent['Year_Bin'].values\n",
        "num_events_recent = len(eruption_years_recent)\n",
        "\n",
        "significant_eruptions_recent.tail()"
      ],
      "metadata": {
        "id": "WNnSc-BpGRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_sea(pca_real_df, eruption_years, pc1_col):\n",
        "    values = pca_real_df.set_index('Year_Bin')[pc1_col]\n",
        "    composite_segments = []\n",
        "    for y in eruption_years:\n",
        "        window = np.arange(y - 3, y + 7)\n",
        "        try:\n",
        "            segment = values.loc[window].values\n",
        "            centered = segment - np.nanmean(segment[:3])  # center on pre-eruption mean\n",
        "            if np.isnan(centered).any():\n",
        "                continue\n",
        "            composite_segments.append(centered)\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if not composite_segments:\n",
        "        return np.full(10, np.nan)\n",
        "    return np.mean(composite_segments, axis=0)\n",
        "\n",
        "def bootstrap_sea(pca_real_df, eruption_years, pc1_col, n=1000):\n",
        "    values = pca_real_df.set_index('Year_Bin')[pc1_col]\n",
        "    all_years = values.index.values\n",
        "    non_eruption_years = [y for y in all_years if y not in eruption_years and y >= min(all_years)+3 and y <= max(all_years)-6]\n",
        "\n",
        "    bootstrapped = []\n",
        "    for _ in range(n):\n",
        "        sampled_years = np.random.choice(non_eruption_years, size=len(eruption_years), replace=False)\n",
        "        segment_means = []\n",
        "        for y in sampled_years:\n",
        "            window = np.arange(y - 3, y + 7)\n",
        "            try:\n",
        "                segment = values.loc[window].values\n",
        "                centered = segment - np.nanmean(segment[:3])\n",
        "                if np.isnan(centered).any():\n",
        "                    break\n",
        "                segment_means.append(centered)\n",
        "            except KeyError:\n",
        "                break\n",
        "        if len(segment_means) == len(eruption_years):\n",
        "            bootstrapped.append(np.mean(segment_means, axis=0))\n",
        "    return np.array(bootstrapped)\n",
        "\n",
        "def run_sea_analysis(pca_df, method_name, pc1_col, eruption_years):\n",
        "    all_real_sea = []\n",
        "    for r in pca_df['Realization'].unique():\n",
        "        pca_real_df = pca_df[pca_df['Realization'] == r]\n",
        "        result = perform_sea(pca_real_df, eruption_years, pc1_col)\n",
        "        all_real_sea.append(result)\n",
        "    all_real_sea = np.array(all_real_sea)\n",
        "\n",
        "    # Mean SEA response across all realizations\n",
        "    sea_median = np.nanmedian(all_real_sea, axis=0)\n",
        "\n",
        "    # Bootstrap null for confidence intervals (from first available realization)\n",
        "    first_real = pca_df['Realization'].unique()[0]\n",
        "\n",
        "    all_boots = []\n",
        "    for r in pca_df['Realization'].unique():\n",
        "        boot = bootstrap_sea(pca_df[pca_df['Realization'] == r], eruption_years, pc1_col, n=5)\n",
        "        all_boots.append(boot)\n",
        "    boot_all = np.concatenate(all_boots, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "    # Confidence intervals (used for shaded plot if needed)\n",
        "    boot_lower = np.percentile(boot_all, 2.5, axis=0)\n",
        "    boot_upper = np.percentile(boot_all, 97.5, axis=0)\n",
        "\n",
        "    return {\n",
        "        'method': method_name,\n",
        "        'years': np.arange(-3, 7),\n",
        "        'median': sea_median,\n",
        "        'boot_lower': boot_lower,\n",
        "        'boot_upper': boot_upper,\n",
        "        'all_real_sea': all_real_sea,\n",
        "        'boot_all': boot_all\n",
        "    }\n",
        "\n",
        "def compute_sea_significance_proportions(all_real_sea, boot_all):\n",
        "    n_realizations = all_real_sea.shape[0]\n",
        "    proportions_pos = []\n",
        "    proportions_neg = []\n",
        "\n",
        "    for t in range(all_real_sea.shape[1]):  # Loop over -3 to +6\n",
        "        real_vals = all_real_sea[:, t]\n",
        "        boot_vals = boot_all[:, t]\n",
        "        upper = np.nanpercentile(boot_vals, 97.5)\n",
        "        lower = np.nanpercentile(boot_vals, 2.5)\n",
        "\n",
        "        # Proportions exceeding null\n",
        "        prop_pos = np.sum(real_vals > upper) / n_realizations\n",
        "        prop_neg = np.sum(real_vals < lower) / n_realizations\n",
        "\n",
        "        proportions_pos.append(prop_pos)\n",
        "        proportions_neg.append(prop_neg)\n",
        "\n",
        "    return np.array(proportions_pos), np.array(proportions_neg)"
      ],
      "metadata": {
        "id": "qOGEQpf88DYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sea_results_recent = []\n",
        "for method, df, pc1_col in [\n",
        "    ('Standard PCA', pca_recent, 'PC1_norm'),\n",
        "    ('Kernel PCA', kpca_recent, 'KPC1_norm'),\n",
        "    ('Wavelet PCA', wpca_recent, 'WPC1_norm')\n",
        "]:\n",
        "    sea_result = run_sea_analysis(df, method, pc1_col, eruption_years_recent)\n",
        "    sea_results_recent.append(sea_result)"
      ],
      "metadata": {
        "id": "o6rrtj_h8F2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_falster_style_sea_cleaned(sea_results, max_realizations_to_plot=100):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    def compute_sea_significance_proportions(all_real_sea, boot_all):\n",
        "        proportions_pos = []\n",
        "        proportions_neg = []\n",
        "        n_realizations = all_real_sea.shape[0]\n",
        "        for t in range(all_real_sea.shape[1]):\n",
        "            real_vals = all_real_sea[:, t]\n",
        "            boot_vals = boot_all[:, t]\n",
        "            upper = np.nanpercentile(boot_vals, 97.5)\n",
        "            lower = np.nanpercentile(boot_vals, 2.5)\n",
        "            prop_pos = np.sum(real_vals > upper) / n_realizations\n",
        "            prop_neg = np.sum(real_vals < lower) / n_realizations\n",
        "            proportions_pos.append(prop_pos)\n",
        "            proportions_neg.append(prop_neg)\n",
        "        return proportions_pos, proportions_neg\n",
        "\n",
        "    def gather_stacked_bar_data(results):\n",
        "        all_methods = []\n",
        "        for res in results:\n",
        "            method = res['method']\n",
        "            years = res['years']\n",
        "            prop_pos, prop_neg = compute_sea_significance_proportions(res['all_real_sea'], res['boot_all'])\n",
        "            for i, year in enumerate(years):\n",
        "                all_methods.append({'Year': year, 'Method': method,\n",
        "                                    'Positive': prop_pos[i], 'Negative': prop_neg[i]})\n",
        "        df = pd.DataFrame(all_methods)\n",
        "\n",
        "        # Sort methods by contribution so that taller bars go last\n",
        "        stacked_pos = []\n",
        "        stacked_neg = []\n",
        "        for year in sorted(df['Year'].unique()):\n",
        "            dfy = df[df['Year'] == year].copy()\n",
        "            dfy = dfy.sort_values(by='Positive', ascending=True)\n",
        "            base = 0\n",
        "            for _, row in dfy.iterrows():\n",
        "                contrib = max(0, row['Positive'] - base)\n",
        "                stacked_pos.append({'Year': year, 'Method': row['Method'], 'Value': contrib, 'Base': base})\n",
        "                base += contrib\n",
        "            dfy = df[df['Year'] == year].copy()\n",
        "            dfy = dfy.sort_values(by='Negative', ascending=True)\n",
        "            base = 0\n",
        "            for _, row in dfy.iterrows():\n",
        "                contrib = max(0, row['Negative'] - base)\n",
        "                stacked_neg.append({'Year': year, 'Method': row['Method'], 'Value': -contrib, 'Base': -base})\n",
        "                base += contrib\n",
        "        return pd.DataFrame(stacked_pos), pd.DataFrame(stacked_neg)\n",
        "\n",
        "    df_pos, df_neg = gather_stacked_bar_data(sea_results)\n",
        "    sea_ref = sea_results[0]\n",
        "    years = sea_ref['years']\n",
        "\n",
        "    method_colors = {\n",
        "        'Standard PCA': '#000004FF',\n",
        "        'Kernel PCA': '#5F187FFF',\n",
        "        'Wavelet PCA': '#D3436EFF'\n",
        "    }\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "    # Draw stacked bars\n",
        "    for method in method_colors:\n",
        "        color = method_colors[method]\n",
        "        dfp = df_pos[df_pos['Method'] == method]\n",
        "        dfn = df_neg[df_neg['Method'] == method]\n",
        "        ax1.bar(dfp['Year'], dfp['Value'], bottom=dfp['Base'], color=color, width=0.8, zorder=1)\n",
        "        ax1.bar(dfn['Year'], dfn['Value'], bottom=dfn['Base'], color=color, width=0.8, zorder=1)\n",
        "\n",
        "    ax1.axhline(0, color='black', zorder=2)\n",
        "    ax1.axvline(0, color='black', linestyle='--', zorder=2)\n",
        "    ax1.set_ylabel('Proportion of Realizations Beyond Null', fontsize=12)\n",
        "    ax1.set_xlabel('Years Relative to Eruption', fontsize=12)\n",
        "    ax1.set_ylim(-1, 1)\n",
        "\n",
        "    # Composite PC1 anomaly\n",
        "    ax2 = ax1.twinx()\n",
        "    ax1.set_zorder(ax2.get_zorder() + 1)\n",
        "    ax1.patch.set_visible(False)\n",
        "    ax2.fill_between(sea_ref['years'], sea_ref['boot_lower'], sea_ref['boot_upper'], color='#8c9cb0', alpha=0.4, zorder=0)\n",
        "    all_real = sea_ref['all_real_sea']\n",
        "    if all_real.shape[0] > max_realizations_to_plot:\n",
        "        sample_idx = np.random.choice(all_real.shape[0], max_realizations_to_plot, replace=False)\n",
        "        all_real = all_real[sample_idx, :]\n",
        "\n",
        "    for line in all_real:\n",
        "        ax2.plot(sea_ref['years'], line, color='gray', alpha=0.8, linewidth=0.7, zorder=3)\n",
        "\n",
        "    all_values = np.concatenate([all_real.flatten(),\n",
        "                                 sea_ref['boot_lower'],\n",
        "                                 sea_ref['boot_upper']])\n",
        "    ci_min = np.nanmin(all_values)\n",
        "    ci_max = np.nanmax(all_values)\n",
        "    range_pad = 0.1 * (ci_max - ci_min)\n",
        "    ax2.set_ylim(ci_min - range_pad, ci_max + range_pad)\n",
        "    ax2.set_ylabel('Composite PC1 Anomaly', fontsize=12)\n",
        "\n",
        "    median_handles = []\n",
        "    median_labels = []\n",
        "\n",
        "    for res in sea_results:\n",
        "        method = res['method']\n",
        "        color = method_colors[method]\n",
        "        line, = ax2.plot(\n",
        "            res['years'], res['median'],\n",
        "            label=f'{method} Median',\n",
        "            color=color, linestyle='--', linewidth=2, zorder=6\n",
        "        )\n",
        "        median_handles.append(line)\n",
        "        median_labels.append(f'{method} Median')\n",
        "\n",
        "    bar_handles = [plt.Line2D([0], [0], color=color, lw=8) for color in method_colors.values()]\n",
        "    bar_labels = list(method_colors.keys())\n",
        "\n",
        "    ci_patch = plt.Rectangle((0, 0), 1, 1, color='#8c9cb0', alpha=0.4, label='95% CI')\n",
        "\n",
        "    handles = bar_handles + median_handles + [ci_patch]\n",
        "    labels = bar_labels + median_labels + ['95% CI']\n",
        "    fig.suptitle(\"Volcanic Forcing on Indo-Pacific Hydroclimate: SEA Median Response and Null Exceedance Proportions\", fontsize=14, y=0.97)\n",
        "    fig.subplots_adjust(bottom=0.1)\n",
        "    fig.legend(handles, labels, loc='lower center', ncol=3, frameon=False)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3nGyUHX6fUlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_falster_style_sea_cleaned(sea_results_recent)"
      ],
      "metadata": {
        "id": "fCTHlmnsfW-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}